# MSCS_634_Lab_6

### üìä Apriori vs. FP-Growth ‚Äì Algorithm Comparison

Both the Apriori and FP-Growth algorithms were applied to the Online Retail dataset using a minimum support threshold of `0.02` and a confidence threshold of `0.5`. The goal was to identify frequent itemsets and generate meaningful association rules.

| Aspect                | Apriori               | FP-Growth             |
|-----------------------|------------------------|------------------------|
| **Runtime**           | Slower                 | ‚úÖ Faster              |
| **Memory Usage**      | Higher (generates many candidates) | ‚úÖ More efficient (uses FP-tree) |
| **Frequent Itemsets** | Identical (same support threshold) | Identical            |
| **Association Rules** | Mostly similar         | Slight differences near threshold |

Apriori generates candidate itemsets level by level and checks their support individually, which increases runtime. FP-Growth compresses the dataset into a prefix-tree structure and extracts patterns more efficiently, leading to faster performance, especially on larger datasets.

---

### ‚è± Efficiency Comparison

In this lab, FP-Growth completed in less time compared to Apriori when mining the same itemsets. The Apriori algorithm finished in approximately 10 seconds while FP-Growth finished in 7. The number of frequent itemsets was the same for both algorithms; however, a few rules generated by FP-Growth differed slightly from Apriori, mostly due to floating-point precision and internal pruning logic near the confidence threshold.

---

### ‚úÖ Insights from Results

- The most frequently purchased items (excluding administrative entries like `POSTAGE`) showed clear co-purchase patterns.
- Association rules with high confidence and lift revealed product pairs that are often bought together (e.g., candle holders and trays).
- Both algorithms provided valuable insights, but FP-Growth achieved them faster and with less computational overhead.

---

### üß† Challenges and Solutions

1. **Misleading Co-occurrence Heatmap**  
   - **Issue**: The initial heatmap showed meaningless co-occurrence due to administrative items like `POSTAGE` inflating frequency.  
   - **Solution**: Removed non-product items before one-hot encoding to clean the dataset.

2. **Flat Transaction Format**  
   - **Issue**: The dataset listed one item per row, not per transaction.  
   - **Solution**: Grouped items by `InvoiceNo` to recreate true transactional baskets.

---

### üèÅ Final Conclusion

Both Apriori and FP-Growth produced high-quality results, but FP-Growth was clearly more efficient. For large or dense datasets, FP-Growth is the preferred algorithm. Apriori remains useful for educational purposes and understanding the step-by-step itemset generation process.
